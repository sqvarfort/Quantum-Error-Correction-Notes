\input{../../UCLHeader.tex}
\input{../../UCLCommands.tex}
\begin{document}
\title{Quantum Error Correction - Lecture 5}
\author{with Dan Browne}
\maketitle
\tableofcontents

\section{Introduction} 
In this lecture, we shall introduce the concept of fault-tolerant quantum computing. We will especially focus on the threshold theorem and emphasise how important efficient scaling methods becomes for fault-tolerant computing. 

\section{The Clifford group}
The concept of a Clifford algebra might sound related. This is a type of associative algebra that generalises the notion of real numbers, complex numbers, quaternions and so on. 

The Clifford group is something else, however. It is the set of unitary gates that maps to stabiliser states. 

What then are stabiliser states? They are states, or codewords in a stabiliser code with $k = 0$. That is, the stabiliser code that does not encode any qubits. This code has the property $n = m$, thus the number of independent stabiliser generators is $m = n$. 

For example, the very simplest code contains the following states and stabilisers. 

\begin{tabular}{ c c}
\hline 
State & Stabiliser \\ \hline
$\ket{0}$ & $Z$ \\ 
$\ket{1}$ & $- Z$ \\ 
$\ket{00} + \ket{11}$ & $XX, ZZ$ \\ 
$\ket{000} + \ket{111}$ & $XXX, ZZI, IZZ$ \\ 
\end{tabular}

For example, the Hadamard gate acts as a stabiliser in that it maps a codeword to the same codespace. 
\beq
H \ket{0} \rightarrow \ket{+}
\eeq
\beq
H \ket{1} \rightarrow \ket{-}
\eeq
We find that $H$ is a Clifford group unitary. So it the $Z$ operator, 
\beq
Z \ket{0} = \ket{0}
\eeq
\beq
Z \ket{1} = - \ket{1}
\eeq
Note the global phase here. It does not affect the stabiliser group since the states $\ket{1}$ and $-\ket{1}$ are experimentally indistinguishable. 
The CNOT gate is another example of a member of the Clifford group. 

Now that we have listed a few gates, we might perhaps rather have a simple way to demonstrate the characteristics of Clifford group gates. We can do so by considering a general operator $\sigma$ as part of the Clifford group and then use a set of unitary matrices $\{U\}$ in a similarity transformation to map the elements of one Puali group to other elements in the Pauli group. That is, 
\beq
\sigma \rightarrow \sigma' = U\sigma U^\dagger
\eeq
where $\sigma$ is some Pauli operator (holds for the $N$-qubit case as well). That is, the Clifford group is the group of unitary matrices that maps elements in the Pauli group to another element in the Pauli group. 


A convenient fact which we shall now prove is that this operation is equivalent to conjugation of the operators. So, a stabiliser $S_j$ fulfils the following relationship
\beq
S_j \ket{\psi} = \ket{\psi}
\eeq
for all $j$. We say that $S_j \in $ the stabiliser group. Consider now 
\beq
U S_j \ket{\psi} = U \ket{\psi}
\eeq
But since we know that $U^\dagger U = \identity$, we can insert this into the expression to find, 
\beq
U S_j U^\dagger U \ket{\psi} = U \ket{\psi}
\eeq
which again holds for all $j$. In fact, $US_j U^\dagger$ is just another stabiliser. 

In order to prove that all the objects that we can obtain for $US_jU$ with different unitary matrices form a group, we need to prove the group properties. First, we have the identity. This is quite clearly filled by the identity matrix $\identity$. Secondly, there exists an inverse since we are dealing with unitary matrices. By conjugating the matrices, we obtain the inverse. Finally, the group is closed because, as we showed, the product $U S_j U^\dagger$ still maps the state $U \ket{\psi}$ to itself. Thus, $US_j U^\dagger$ is also a stabiliser, and the group is closed. 

Let us have a look at another gate which is a member of the Clifford group. This is the $S$-gate, given by 
\beq
S = \bpmat 1 & 0 \\ 0 & i \epmat
\eeq
We find that $S \in$ the Clifford group, since 
\beq
S Z S^\dagger = S
\eeq
That is, $S$ maps $Z$ to itself, and thus stays in the Clifford group. This can be easily confirmed since $[S, Z]= 0$. 

The $S$ gate has the following effect. 
\beq
S \ket{+} = \ket{+i}
\eeq
\beq
S \ket{+i} = \ket{-}
\eeq
On the Bloch sphere, the $S$ gate can be thought of as a rotation of 90 degrees on the equator. 

For a single qubit, the Clifford group is generated by $H$ and $S$. This is all we need. 

Recall that the stabiliser states in the single qubit group lie on an octahedron in the Bloch sphere - one for each axial extremal point. Thus, the symmetry group for the stabilisers is the symmetry group of the octahedron. Here, all $X,Y,Z$ are rotations of 180 degrees around a certain axis. The Hadamard gate is a reflection about a diagonal line. 

However, we want to be able to go from the single qubit Clifford group to the $N$-qubit Clifford group. It turns out that it is generated by the set
\beq
\{H, S, CNOT\}
\eeq
which must act on every qubit and every pair of qubits. Note the similarity between this set and the universal quantum computing gate set. 

We now wish to prove that the CNOT gate is a meber of the Clifford group. It suffices to check that 
\beq
U \sigma U^\dagger = \sigma' 
\eeq
where $\sigma$ is some Pauli operator. We use the following notation $CNOT_{CT}$ where $C$ is the control qubit and $T$ is the target qubit. We know that CNOT is self-inverse. We can check that 
\beq
CNOT_{CT} ( Z\otimes I) CNOT_{CT} = I \otimes Z
\eeq
The control commutes with $Z$ gates. WE also find that 
\beq
CNOT ( X \otimes I ) CNOT = X\otimes X
\eeq
\beq
CNOT(I \otimes Z ) CNOT = Z\otimes Z
\eeq
Note that the commutator relations are preserved. Finally, 
\beq
CNOT(I\otimes X)CNOT = I \otimes X
\eeq
Since we proved this for generators of the Pauli group, we know it applies to the entire group. 

\section{Gottesmann-Knill Theorem}
Theorem: The Clifford group circuits acting on stabiliser states are easy to simulate classically. Any quantum circuit on $n$ qubits acting on an initial stabiliser state consisting of a polynomial in $n$ different gates can be effectively simulated in $\mathcal{O}(n)$ gates on a classical computer. 

\emph{Proof idea}: We shall here not prove the entire theorem, but rather give a flavour of the proof ingredients. 
\begin{itemize}
\item Represent states by stabiliser generators and show that we end up with unitary update rules. 
\item Then, must show that the measurement update rules are all efficiently simulatable. 
\end{itemize}

The consequences are substantial. It shows that Clifford gates, stabiliser states and the Pauli group is not enough for universal quantum computing. 

So given stabiliser states, Clifford unitaries and Pauli measurements, what must we add for true universal computing? 

It turns out that we need to add a single non-Clifford unitary. We can consider using a non-stabiliser states as an ancilla, or performing some non-Pauli measurements to achieve this. It is usually enough to add just one of these components. 

We paraphrase the following theorem:

\textbf{Theorem}: (Nebe, Rains, Sloane) Given a non-Clifford unitary $U$, the set
\beq
\{U, U^\dagger, CNOT, H, S\}
\eeq
is approximately universal. 

It means that we can approximate universality with other sets. A gate set is approximately universal if any unitary $U$ can be approximated to arbitrary accuracy by a gate sequence contained in the set. 

So, by using the set above, we can \emph{efficiently} simulate any other set, thus gaining approximate universality. As long we are happy with a little bit of error. 

\section{The Solovay-Kitaev theorem}
Again, we paraphrase this theorem: Given a set (single qubit) of unitarieis which is approximately universal for single qubit quantum computing, we can represent an arbitrary single qubit unitary to arbitrary accuracy \emph{efficiently}. 

That is, if $U$ is our target unitary, $S$ is our unitary achieved as a sequence of gates, and we want
\beq
\norm{S - U}< \epsilon
\eeq
where the norm is
\beq
\norm{S - U } = \max_{\ket{\psi}} \norm{S \ket{\psi} - U \ket{\psi} }
\eeq
It turns out that it suffices to use a sequence of length $\mathcal{O} \left( \log^c{\frac{1}{\epsilon}} \right)$ where $c \simeq 1.7$. Here, the scaling is the important thing -- it shows that the process is efficient. 

So we just need a unitary $U$ gate set to efficiently simulate anything. 

What then, shall we use? We can make use of the so-called $T$ gate. 
It is defined as
\beq
T = \sqrt{S}
\eeq
If we write
\beq
S = \bpmat 1 & 0 \\ 0 & e^{i \pi/2} \epmat
\eeq
Then
\beq
T = \bpmat 1 & 0 \\ 0 & e^{i \pi /4} \epmat
\eeq
It is also known as a $\pi/8$ gate because we could write
\beq
T= e^{i \pi /8}\bpmat e^{- i \pi/8} &0 \\ 0 & e^{i \pi/8}
\epmat
\eeq
However, the name $T$-gate is the more common jargon. This is a non-Cliford gate with many more properties. We know that
\beq
T^2 = S
\eeq
Also, for $T $ and $T^\dagger$, it follows
\beq
T^\dagger = T^\dagger T^\dagger T = S^\dagger T = S¨\dagger S¨\dagger S T = ZST
\eeq
So we can obtain the inverse by multiplication of other gates. This becomes very clear if we view it in the Bloch sphere. 

As a result, we can conclude that the set $\{CNOT, H, T\}$ is an approximately universal set. For fault tolerance, it is very useful to have a universal gate set. In general, we can approximate any small evolution as 
\beq
e^{i Ht} \simeq I + i Ht
\eeq
That is, we divide it up into gates. 

\section{Fault-Tolerant Quantum Computing}
We first introduce the Threshold Theorem. There exist many implementations of it, but we shall use a simple error model to demonstrate its purpose. 

\textbf{Threshold Theorem}: Assume the following simplified error model: Every component in our computation, e.g. the preparation of input states, unitary gates, and measurements. 

Assume that every component succeeds with probability $1-p$ and fails with probability $p$. We take this probability to be very small $p\ll 1$. 

Here, fail means that the gate is followed by an arbitrary error -- anything can happen. If we use quantum error correcting codes, concatenation or similar, frequent error correction, we need a fault-tolerant construction to stop errors from spreading. 

We find that certain methods cause errors to spread to the extent that they multiply. We thus need to prevent single errors from turning into multiple errors. 

Given all this, efficient, reliable quantum computation is possible provided
\beq
p<p_{th}
\eeq
where $p_{th}$ is a threshold rate. Then, the errors will be suppressed through correction. 

How would we do this? It turns out that we only need a code that can correct a single error.  The key idea is that we use a distance 3 code that allows us to correct one error and call the set of qubits supporting the code a code block. 

For example, we can take the Steane code, $n = 7, d = 3, k = 1)$. Here, let 7 qubit represent a code block - this is one single encoded qubit. Then, in order to implement a fault-tolerant design, we would try and ensure that the probability of more than one error in each code block is heavily suppressed. 

So fault-tolerant constructions want to design circuits such that one component failure leads to at most one error on one single qubit in one separate code block. 

The key idea is the following. It means that if this is achieved, a code block will only fail to have its error corrected if two or more independent component failures occur. This notion of \textbf{independence} is very important. 

If a component failure rate is $p$, then the probability of wo independent failures is $p^2$, which is indeed very small. We can do the same kind of analysis with $d>3$ codes. 

This means estimating the probability of a code block failure occuring. It will be 
\beq
p^2 \times \mbox{no. of pairs or error locations}
\eeq
where the second term simply means all the possible things that can go wrong. We must consider every component as an error location., e.g. the number of pairs of failed components which cause code blocks to fail.

For example, we can look at the encoded CNOT gate in the Steane code. Since the CNOT gate operates on two logical qubits, it must act on two separate code blocks. After we act with the CNOT gate, we must measure each code block for an error and then correct them individually. 

Counting all pairs of errors that can occur gives us about $\sim 10^4$. If we then calculate the probability of an error occuring times the number of ways in which this can happen, we get
\beq
\left( 10^4 \cdot 10^{-4} \right)^2 = 1
\eeq
We would want this quantity to be really small, preferably smaller than 1. 

But note that our one layer of encoding has brought us from $p$ to $p^2$. We write
\beq
cp^2
\eeq
where $c$ denotes pairs of error locations. 

\section{Code concatenation}
We replace every qubit by a code-block and every component by an encoded CNOT gate. We worked out before that we got $cp^2$ for one layer. For two layers of encoding, we gain
\beq
cp^2 \rightarrow c \left( cp^2 \right)^2 = c^3 p^4 = \frac{(cp)^4}{c}\eeq
Then, we go from $2 \rightarrow 2\cdot 7 \rightarrow 2 \cdot 7^2$ qubits in the case of the Steane code. 

We can then repeat the concatenation. After $n$ layers of encoding, we have
\beq
\frac{(cp)^{2^n}}{c}
\eeq
Now, if $cp<1$, this quantity gets exponentially suppressed. However, we do end up having to use $2\cdot 7^n$ qubits for the encoding. We can show though that the error grows slower than the number of qubits. 

More generally, let $d$ be the size of a code block. We then get a number of $d^n$ physical qubits and gates that scale with $d^n$. It is not too bad, considering that the error quantity scaled with $2^n$, which is much faster. 

Consider then a quantum algorithm with problem size $n$ and $f(n)$ number of polynomial components. We can accept an overall error $\calE$, where $\calE$ must not scale with $n$. Thus, if we repeat the algorithm, we bring down the error. This is the case for e.g. Grover's unstructured search algorithm. Note that by problem size, we mean the parameter that determines the complexity of hte problem. 

The encoded component error at the top layer is $p$. Then, the probability of all components succeeding for a number of $f(n)$ operations is
\beq
(1- p)^{f(n)} \simeq 1 - pf(n)
\eeq
So here, we want $pf(n) \ll \calE$. To explore this more closely, set $p = \epsilon$, where
\beq
\epsilon = \frac{(cp)^{2^n}}{c}
\eeq
is the quantity we considered before. So then, for $k$ levels of encoding (we switch the name of the variable since $n$ is already taken), we get
\beq
\frac{(cp)^{2^k}}{c} f(n) \ll \calE
\eeq
We can solve this for $k$, see Nielsen and Chuang Section 10.6 for details. However, the overhead from encoding is $d^k$, and we can show that
\beq
d^k = \cal{O} \left( poly \left( \log{f(n)/\epsilon} / \calE \right) f(n) \right)
\eeq
which is approximately $Polyl(\log{n})$, so it's actually pretty good. Thus, provided we can encode everything, all our gates and all the qubits, we can have fault-tolerant computing. 

However, the architecture for such a system is difficult, and the overhead is difficult. 

Question: What is meant by overhead? I don't seem to have written that down. 








\end{document}